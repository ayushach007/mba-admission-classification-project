{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Classification Model BUilding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import necessary modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from dotenv.main import load_dotenv\n",
    "\n",
    "# sql connection library\n",
    "import mysql.connector as mysql\n",
    "\n",
    "# feature engineering library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# model building library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (RandomForestClassifier,\n",
    "                            AdaBoostClassifier,\n",
    "                            GradientBoostingClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# model evaluation library\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# model tuning library\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# save model\n",
    "import joblib\n",
    "\n",
    "# load env\n",
    "load_dotenv()\n",
    "\n",
    "# ignore warning\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load the data from database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # connect to database\n",
    "    conn = mysql.connect(user = os.getenv('MYSQL_USER'), password = os.getenv('MYSQL_PASSWORD'), host = os.getenv('MYSQL_HOST'), database = os.getenv('MYSQL_DATABASE'))\n",
    "    # convert to dataframe\n",
    "    df = pd.read_sql('SELECT * FROM admission', con = conn)\n",
    "    # close connection\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>international</th>\n",
       "      <th>gpa</th>\n",
       "      <th>major</th>\n",
       "      <th>race</th>\n",
       "      <th>gmat</th>\n",
       "      <th>work_exp</th>\n",
       "      <th>work_industry</th>\n",
       "      <th>admission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Business</td>\n",
       "      <td>Asian</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.28</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>Black</td>\n",
       "      <td>680.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Investment Management</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>True</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Business</td>\n",
       "      <td></td>\n",
       "      <td>710.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.47</td>\n",
       "      <td>STEM</td>\n",
       "      <td>Black</td>\n",
       "      <td>690.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Technology</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.35</td>\n",
       "      <td>STEM</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>590.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Consulting</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_id  gender  ...          work_industry  admission\n",
       "0               1  Female  ...     Financial Services      Admit\n",
       "1               2    Male  ...  Investment Management           \n",
       "2               3  Female  ...             Technology      Admit\n",
       "3               4    Male  ...             Technology           \n",
       "4               5    Male  ...             Consulting           \n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the blank values with appropriate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'] = df['race'].replace('', 'Unknown')\n",
    "df['admission'] = df['admission'].replace('', 'Reject')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the features and target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['admission'], axis = 1)\n",
    "y = df['admission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>international</th>\n",
       "      <th>gpa</th>\n",
       "      <th>major</th>\n",
       "      <th>race</th>\n",
       "      <th>gmat</th>\n",
       "      <th>work_exp</th>\n",
       "      <th>work_industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Business</td>\n",
       "      <td>Asian</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Financial Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.28</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>Black</td>\n",
       "      <td>680.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Investment Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>True</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Business</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>710.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.47</td>\n",
       "      <td>STEM</td>\n",
       "      <td>Black</td>\n",
       "      <td>690.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.35</td>\n",
       "      <td>STEM</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>590.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Consulting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_id  gender international  ...   gmat work_exp          work_industry\n",
       "0               1  Female         False  ...  620.0      3.0     Financial Services\n",
       "1               2    Male         False  ...  680.0      5.0  Investment Management\n",
       "2               3  Female          True  ...  710.0      5.0             Technology\n",
       "3               4    Male         False  ...  690.0      6.0             Technology\n",
       "4               5    Male         False  ...  590.0      5.0             Consulting\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Admit\n",
       "1    Reject\n",
       "2     Admit\n",
       "3    Reject\n",
       "4    Reject\n",
       "Name: admission, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique categories in categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender : ['Female' 'Male']\n",
      "\n",
      "international : ['False' 'True']\n",
      "\n",
      "major : ['Business' 'Humanities' 'STEM']\n",
      "\n",
      "race : ['Asian' 'Black' 'Unknown' 'Hispanic' 'White' 'Other']\n",
      "\n",
      "work_industry : ['Financial Services' 'Investment Management' 'Technology' 'Consulting'\n",
      " 'Nonprofit/Gov' 'PE/VC' 'Health Care' 'Investment Banking' 'Other'\n",
      " 'Retail' 'Energy' 'CPG' 'Real Estate' 'Media/Entertainment']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "for feature in categorical_features:\n",
    "    print(f'{feature} : {df[feature].unique()}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **There are fewer unique categories in each column except for work industry, so we'll try both one-hot and ordinal encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle numeric and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column transformer to preprocess data\n",
    "\n",
    "# numerical features\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# categorical features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# numerical pipeline\n",
    "num_pipeline = Pipeline(\n",
    "    steps =[\n",
    "\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "# categorical pipeline\n",
    "cat_pipeline = Pipeline(\n",
    "    steps= [\n",
    "\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)),\n",
    "        ('scaler', StandardScaler())\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "# full pipeline using column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "\n",
    "    ('num', num_pipeline, numeric_features),\n",
    "    ('cat', cat_pipeline, categorical_features)\n",
    "    \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform preprocessor on input data\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# fit and transform label encoder on target data\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4335, 26), (1859, 26), (4335,), (1859,))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform oversampling for training data\n",
    "sm = SMOTE()\n",
    "\n",
    "X_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to evaluate model\n",
    "def evaluate_model(actual, pred):\n",
    "    '''\n",
    "    Function to evaluate model performance\n",
    "\n",
    "    Args:\n",
    "    actual : Actual/True label\n",
    "    pred : Predicted label\n",
    "\n",
    "    Returns:\n",
    "    accuracy : accuracy score\n",
    "    matrix : confusion matrix\n",
    "    report : classification report\n",
    "    '''\n",
    "    accuracy = accuracy_score(actual, pred)\n",
    "    matrix = confusion_matrix(actual, pred)\n",
    "    report = classification_report(actual, pred)\n",
    "    \n",
    "    return accuracy, matrix, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.6200599618424639\n",
      "\n",
      "- Confusion matrix: \n",
      "[[2053  559 1057]\n",
      " [ 598 2520  551]\n",
      " [ 856  561 2252]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.56      0.57      3669\n",
      "           1       0.69      0.69      0.69      3669\n",
      "           2       0.58      0.61      0.60      3669\n",
      "\n",
      "    accuracy                           0.62     11007\n",
      "   macro avg       0.62      0.62      0.62     11007\n",
      "weighted avg       0.62      0.62      0.62     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.6557288864981172\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 159   55   85]\n",
      " [ 241 1046  238]\n",
      " [   8   13   14]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.53      0.45       299\n",
      "           1       0.94      0.69      0.79      1525\n",
      "           2       0.04      0.40      0.08        35\n",
      "\n",
      "    accuracy                           0.66      1859\n",
      "   macro avg       0.46      0.54      0.44      1859\n",
      "weighted avg       0.83      0.66      0.72      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "1.0\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3669    0    0]\n",
      " [   0 3669    0]\n",
      " [   0    0 3669]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3669\n",
      "           1       1.00      1.00      1.00      3669\n",
      "           2       1.00      1.00      1.00      3669\n",
      "\n",
      "    accuracy                           1.00     11007\n",
      "   macro avg       1.00      1.00      1.00     11007\n",
      "weighted avg       1.00      1.00      1.00     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.8230231307154384\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 142  154    3]\n",
      " [ 137 1386    2]\n",
      " [  13   20    2]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.47      0.48       299\n",
      "           1       0.89      0.91      0.90      1525\n",
      "           2       0.29      0.06      0.10        35\n",
      "\n",
      "    accuracy                           0.82      1859\n",
      "   macro avg       0.55      0.48      0.49      1859\n",
      "weighted avg       0.81      0.82      0.82      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.7859543926592168\n",
      "\n",
      "- Confusion matrix: \n",
      "[[2960  278  431]\n",
      " [ 684 2929   56]\n",
      " [ 838   69 2762]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73      3669\n",
      "           1       0.89      0.80      0.84      3669\n",
      "           2       0.85      0.75      0.80      3669\n",
      "\n",
      "    accuracy                           0.79     11007\n",
      "   macro avg       0.80      0.79      0.79     11007\n",
      "weighted avg       0.80      0.79      0.79     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.764389456697149\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 202   84   13]\n",
      " [ 282 1213   30]\n",
      " [  19   10    6]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.68      0.50       299\n",
      "           1       0.93      0.80      0.86      1525\n",
      "           2       0.12      0.17      0.14        35\n",
      "\n",
      "    accuracy                           0.76      1859\n",
      "   macro avg       0.48      0.55      0.50      1859\n",
      "weighted avg       0.83      0.76      0.79      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.8989733805759971\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3261  213  195]\n",
      " [ 453 3210    6]\n",
      " [ 217   28 3424]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      3669\n",
      "           1       0.93      0.87      0.90      3669\n",
      "           2       0.94      0.93      0.94      3669\n",
      "\n",
      "    accuracy                           0.90     11007\n",
      "   macro avg       0.90      0.90      0.90     11007\n",
      "weighted avg       0.90      0.90      0.90     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.7966648735879505\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 178  117    4]\n",
      " [ 219 1299    7]\n",
      " [  16   15    4]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.60      0.50       299\n",
      "           1       0.91      0.85      0.88      1525\n",
      "           2       0.27      0.11      0.16        35\n",
      "\n",
      "    accuracy                           0.80      1859\n",
      "   macro avg       0.54      0.52      0.51      1859\n",
      "weighted avg       0.82      0.80      0.80      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "SVM\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.902516580357954\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3369  102  198]\n",
      " [ 648 2904  117]\n",
      " [   8    0 3661]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88      3669\n",
      "           1       0.97      0.79      0.87      3669\n",
      "           2       0.92      1.00      0.96      3669\n",
      "\n",
      "    accuracy                           0.90     11007\n",
      "   macro avg       0.91      0.90      0.90     11007\n",
      "weighted avg       0.91      0.90      0.90     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.7170521785906401\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 182   81   36]\n",
      " [ 321 1149   55]\n",
      " [  18   15    2]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.61      0.44       299\n",
      "           1       0.92      0.75      0.83      1525\n",
      "           2       0.02      0.06      0.03        35\n",
      "\n",
      "    accuracy                           0.72      1859\n",
      "   macro avg       0.43      0.47      0.43      1859\n",
      "weighted avg       0.81      0.72      0.75      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "1.0\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3669    0    0]\n",
      " [   0 3669    0]\n",
      " [   0    0 3669]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3669\n",
      "           1       1.00      1.00      1.00      3669\n",
      "           2       1.00      1.00      1.00      3669\n",
      "\n",
      "    accuracy                           1.00     11007\n",
      "   macro avg       1.00      1.00      1.00     11007\n",
      "weighted avg       1.00      1.00      1.00     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.7875201721355568\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 138  151   10]\n",
      " [ 182 1324   19]\n",
      " [  18   15    2]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.46      0.43       299\n",
      "           1       0.89      0.87      0.88      1525\n",
      "           2       0.06      0.06      0.06        35\n",
      "\n",
      "    accuracy                           0.79      1859\n",
      "   macro avg       0.45      0.46      0.46      1859\n",
      "weighted avg       0.80      0.79      0.79      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "KNN\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.9248659943672208\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3637    8   24]\n",
      " [ 685 2874  110]\n",
      " [   0    0 3669]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      3669\n",
      "           1       1.00      0.78      0.88      3669\n",
      "           2       0.96      1.00      0.98      3669\n",
      "\n",
      "    accuracy                           0.92     11007\n",
      "   macro avg       0.93      0.92      0.92     11007\n",
      "weighted avg       0.93      0.92      0.92     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.6659494351802044\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 171   99   29]\n",
      " [ 387 1066   72]\n",
      " [  17   17    1]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.57      0.39       299\n",
      "           1       0.90      0.70      0.79      1525\n",
      "           2       0.01      0.03      0.01        35\n",
      "\n",
      "    accuracy                           0.67      1859\n",
      "   macro avg       0.40      0.43      0.40      1859\n",
      "weighted avg       0.79      0.67      0.71      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBoost\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.9960025438357409\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3637   30    2]\n",
      " [  12 3657    0]\n",
      " [   0    0 3669]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3669\n",
      "           1       0.99      1.00      0.99      3669\n",
      "           2       1.00      1.00      1.00      3669\n",
      "\n",
      "    accuracy                           1.00     11007\n",
      "   macro avg       1.00      1.00      1.00     11007\n",
      "weighted avg       1.00      1.00      1.00     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.8267885960193653\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 122  176    1]\n",
      " [ 109 1412    4]\n",
      " [  13   19    3]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.41      0.45       299\n",
      "           1       0.88      0.93      0.90      1525\n",
      "           2       0.38      0.09      0.14        35\n",
      "\n",
      "    accuracy                           0.83      1859\n",
      "   macro avg       0.58      0.47      0.50      1859\n",
      "weighted avg       0.81      0.83      0.81      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression' : LogisticRegression(),\n",
    "    'Random Forest' : RandomForestClassifier(),\n",
    "    'AdaBoost' : AdaBoostClassifier(),\n",
    "    'Gradient Boosting' : GradientBoostingClassifier(),\n",
    "    'SVM' : SVC(),\n",
    "    'Decision Tree' : DecisionTreeClassifier(),\n",
    "    'KNN' : KNeighborsClassifier(),\n",
    "    'XGBoost' : XGBClassifier()\n",
    "}\n",
    "\n",
    "model_list = []\n",
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values()) [i]\n",
    "    model.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "    # make predictions\n",
    "    y_train_pred = model.predict(X_train_oversampled)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # evaluate train and test performance\n",
    "    train_model_accuracy, train_model_matrix, train_model_report = evaluate_model(y_train_oversampled, y_train_pred)\n",
    "    test_model_accuracy, test_model_matrix, test_model_report = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(f\"- Accuracy: \\n{train_model_accuracy}\", end='\\n\\n')\n",
    "    print(f\"- Confusion matrix: \\n{train_model_matrix}\", end='\\n\\n')\n",
    "    print(f\"- Classification report: \\n{train_model_report}\", end='\\n\\n')\n",
    "    train_accuracy_list.append(train_model_accuracy)\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(f\"- Accuracy: \\n{test_model_accuracy}\", end='\\n\\n')\n",
    "    print(f\"- Confusion matrix: \\n {test_model_matrix}\", end='\\n\\n')\n",
    "    print(f\"- Classification report: \\n {test_model_report}\", end='\\n\\n')\n",
    "    test_accuracy_list.append(test_model_accuracy)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Models Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.826789</td>\n",
       "      <td>0.996003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.823023</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.796665</td>\n",
       "      <td>0.898973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.787520</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.764389</td>\n",
       "      <td>0.785954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.717052</td>\n",
       "      <td>0.902517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.665949</td>\n",
       "      <td>0.924866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.655729</td>\n",
       "      <td>0.620060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Test Accuracy  Train Accuracy\n",
       "7              XGBoost       0.826789        0.996003\n",
       "1        Random Forest       0.823023        1.000000\n",
       "3    Gradient Boosting       0.796665        0.898973\n",
       "5        Decision Tree       0.787520        1.000000\n",
       "2             AdaBoost       0.764389        0.785954\n",
       "4                  SVM       0.717052        0.902517\n",
       "6                  KNN       0.665949        0.924866\n",
       "0  Logistic Regression       0.655729        0.620060"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(list(zip(model_list, test_accuracy_list, train_accuracy_list)), columns=['Model', 'Test Accuracy', 'Train Accuracy']).sort_values(by=['Test Accuracy', 'Train Accuracy'], ascending=False)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Most of the models are overfitting and LR is underfitting, so we'll choose AdaBoost for this problem statement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoost is 0.8187197417966648\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  66  232    1]\n",
      " [  65 1456    4]\n",
      " [   6   29    0]]\n"
     ]
    }
   ],
   "source": [
    "# prediction for actual data\n",
    "ada_boost = AdaBoostClassifier()\n",
    "ada_boost.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ada_boost.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy of AdaBoost is {score}', end='\\n\\n')\n",
    "print(f'Confusion Matrix: \\n {matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoost is 0.764389456697149\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 202   84   13]\n",
      " [ 282 1213   30]\n",
      " [  19   10    6]]\n"
     ]
    }
   ],
   "source": [
    "# prediction for oversampled data\n",
    "ada_boost = AdaBoostClassifier()\n",
    "ada_boost.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "y_pred = ada_boost.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy of AdaBoost is {score}', end='\\n\\n')\n",
    "print(f'Confusion Matrix: \\n {matrix}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "admission",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
