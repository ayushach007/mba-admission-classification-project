{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Classification Model BUilding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import necessary modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from dotenv.main import load_dotenv\n",
    "\n",
    "# sql connection library\n",
    "import mysql.connector as mysql\n",
    "\n",
    "# feature engineering library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# model building library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (RandomForestClassifier,\n",
    "                            AdaBoostClassifier,\n",
    "                            GradientBoostingClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# model evaluation library\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# model tuning library\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# save model\n",
    "import joblib\n",
    "\n",
    "# load env\n",
    "load_dotenv()\n",
    "\n",
    "# ignore warning\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load the data from database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # connect to database\n",
    "    conn = mysql.connect(user = os.getenv('MYSQL_USER'), password = os.getenv('MYSQL_PASSWORD'), host = os.getenv('MYSQL_HOST'), database = os.getenv('MYSQL_DATABASE'))\n",
    "    # convert to dataframe\n",
    "    df = pd.read_sql('SELECT * FROM admission', con = conn)\n",
    "    # close connection\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>international</th>\n",
       "      <th>gpa</th>\n",
       "      <th>major</th>\n",
       "      <th>race</th>\n",
       "      <th>gmat</th>\n",
       "      <th>work_exp</th>\n",
       "      <th>work_industry</th>\n",
       "      <th>admission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Business</td>\n",
       "      <td>Asian</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.28</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>Black</td>\n",
       "      <td>680.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Investment Management</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>True</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Business</td>\n",
       "      <td></td>\n",
       "      <td>710.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.47</td>\n",
       "      <td>STEM</td>\n",
       "      <td>Black</td>\n",
       "      <td>690.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Technology</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.35</td>\n",
       "      <td>STEM</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>590.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Consulting</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_id  gender international   gpa       major      race   gmat  \\\n",
       "0               1  Female         False  3.30    Business     Asian  620.0   \n",
       "1               2    Male         False  3.28  Humanities     Black  680.0   \n",
       "2               3  Female          True  3.30    Business            710.0   \n",
       "3               4    Male         False  3.47        STEM     Black  690.0   \n",
       "4               5    Male         False  3.35        STEM  Hispanic  590.0   \n",
       "\n",
       "   work_exp          work_industry admission  \n",
       "0       3.0     Financial Services     Admit  \n",
       "1       5.0  Investment Management            \n",
       "2       5.0             Technology     Admit  \n",
       "3       6.0             Technology            \n",
       "4       5.0             Consulting            "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the blank values with appropriate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'] = df['race'].replace('', 'Unknown')\n",
    "df['admission'] = df['admission'].replace('', 'Reject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>international</th>\n",
       "      <th>gpa</th>\n",
       "      <th>major</th>\n",
       "      <th>race</th>\n",
       "      <th>gmat</th>\n",
       "      <th>work_exp</th>\n",
       "      <th>work_industry</th>\n",
       "      <th>admission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Business</td>\n",
       "      <td>Asian</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.28</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>Black</td>\n",
       "      <td>680.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Investment Management</td>\n",
       "      <td>Reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>True</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Business</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>710.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.47</td>\n",
       "      <td>STEM</td>\n",
       "      <td>Black</td>\n",
       "      <td>690.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.35</td>\n",
       "      <td>STEM</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>590.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>Reject</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_id  gender international   gpa       major      race   gmat  \\\n",
       "0               1  Female         False  3.30    Business     Asian  620.0   \n",
       "1               2    Male         False  3.28  Humanities     Black  680.0   \n",
       "2               3  Female          True  3.30    Business   Unknown  710.0   \n",
       "3               4    Male         False  3.47        STEM     Black  690.0   \n",
       "4               5    Male         False  3.35        STEM  Hispanic  590.0   \n",
       "\n",
       "   work_exp          work_industry admission  \n",
       "0       3.0     Financial Services     Admit  \n",
       "1       5.0  Investment Management    Reject  \n",
       "2       5.0             Technology     Admit  \n",
       "3       6.0             Technology    Reject  \n",
       "4       5.0             Consulting    Reject  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admission\n",
       "Reject      5194\n",
       "Admit        900\n",
       "Waitlist     100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.admission.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the features and target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['admission', 'application_id'], axis = 1)\n",
    "y = df['admission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>international</th>\n",
       "      <th>gpa</th>\n",
       "      <th>major</th>\n",
       "      <th>race</th>\n",
       "      <th>gmat</th>\n",
       "      <th>work_exp</th>\n",
       "      <th>work_industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Business</td>\n",
       "      <td>Asian</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Financial Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.28</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>Black</td>\n",
       "      <td>680.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Investment Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>True</td>\n",
       "      <td>3.30</td>\n",
       "      <td>Business</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>710.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.47</td>\n",
       "      <td>STEM</td>\n",
       "      <td>Black</td>\n",
       "      <td>690.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>3.35</td>\n",
       "      <td>STEM</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>590.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Consulting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender international   gpa       major      race   gmat  work_exp  \\\n",
       "0  Female         False  3.30    Business     Asian  620.0       3.0   \n",
       "1    Male         False  3.28  Humanities     Black  680.0       5.0   \n",
       "2  Female          True  3.30    Business   Unknown  710.0       5.0   \n",
       "3    Male         False  3.47        STEM     Black  690.0       6.0   \n",
       "4    Male         False  3.35        STEM  Hispanic  590.0       5.0   \n",
       "\n",
       "           work_industry  \n",
       "0     Financial Services  \n",
       "1  Investment Management  \n",
       "2             Technology  \n",
       "3             Technology  \n",
       "4             Consulting  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admission\n",
       "Reject      5194\n",
       "Admit        900\n",
       "Waitlist     100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique categories in categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender : ['Female' 'Male']\n",
      "\n",
      "international : ['False' 'True']\n",
      "\n",
      "major : ['Business' 'Humanities' 'STEM']\n",
      "\n",
      "race : ['Asian' 'Black' 'Unknown' 'Hispanic' 'White' 'Other']\n",
      "\n",
      "work_industry : ['Financial Services' 'Investment Management' 'Technology' 'Consulting'\n",
      " 'Nonprofit/Gov' 'PE/VC' 'Health Care' 'Investment Banking' 'Other'\n",
      " 'Retail' 'Energy' 'CPG' 'Real Estate' 'Media/Entertainment']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "for feature in categorical_features:\n",
    "    print(f'{feature} : {df[feature].unique()}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **There are fewer unique categories in each column except for work industry, so we'll try both one-hot and ordinal encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle numeric and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column transformer to preprocess data\n",
    "\n",
    "# numerical features\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# categorical features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "df['race'] = df['race'].replace('', 'Unknown')\n",
    "df['admission'] = df['admission'].replace('', 'Reject')\n",
    "\n",
    "# numerical pipeline\n",
    "num_pipeline = Pipeline(\n",
    "    steps =[\n",
    "\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "# categorical pipeline\n",
    "cat_pipeline = Pipeline(\n",
    "    steps= [\n",
    "\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)),\n",
    "        ('scaler', StandardScaler())\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "# full pipeline using column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "\n",
    "    ('num', num_pipeline, numeric_features),\n",
    "    ('cat', cat_pipeline, categorical_features)\n",
    "    \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform preprocessor on input data\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# fit and transform label encoder on target data\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform oversampling for training data\n",
    "sm = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure categorical features are encoded before resampling\n",
    "X_res, y_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15582, 25), (15582,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape, y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get back original data\n",
    "X_res = pd.DataFrame(X_res, columns = numeric_features.tolist() + list(preprocessor.named_transformers_['cat'].named_steps['encoder'].get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpa</th>\n",
       "      <th>gmat</th>\n",
       "      <th>work_exp</th>\n",
       "      <th>x0_Male</th>\n",
       "      <th>x1_True</th>\n",
       "      <th>x2_Humanities</th>\n",
       "      <th>x2_STEM</th>\n",
       "      <th>x3_Black</th>\n",
       "      <th>x3_Hispanic</th>\n",
       "      <th>x3_Other</th>\n",
       "      <th>...</th>\n",
       "      <th>x4_Health Care</th>\n",
       "      <th>x4_Investment Banking</th>\n",
       "      <th>x4_Investment Management</th>\n",
       "      <th>x4_Media/Entertainment</th>\n",
       "      <th>x4_Nonprofit/Gov</th>\n",
       "      <th>x4_Other</th>\n",
       "      <th>x4_PE/VC</th>\n",
       "      <th>x4_Real Estate</th>\n",
       "      <th>x4_Retail</th>\n",
       "      <th>x4_Technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.325261</td>\n",
       "      <td>-0.630806</td>\n",
       "      <td>-1.953750</td>\n",
       "      <td>-1.323505</td>\n",
       "      <td>-0.650579</td>\n",
       "      <td>-0.817431</td>\n",
       "      <td>-0.658884</td>\n",
       "      <td>-0.416594</td>\n",
       "      <td>-0.326292</td>\n",
       "      <td>-0.199462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23874</td>\n",
       "      <td>-0.321424</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-0.098066</td>\n",
       "      <td>-0.342703</td>\n",
       "      <td>-0.270048</td>\n",
       "      <td>-0.414189</td>\n",
       "      <td>-0.135084</td>\n",
       "      <td>-0.073187</td>\n",
       "      <td>-0.361531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.193273</td>\n",
       "      <td>0.586457</td>\n",
       "      <td>-0.016421</td>\n",
       "      <td>0.755569</td>\n",
       "      <td>-0.650579</td>\n",
       "      <td>1.223345</td>\n",
       "      <td>-0.658884</td>\n",
       "      <td>2.400418</td>\n",
       "      <td>-0.326292</td>\n",
       "      <td>-0.199462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23874</td>\n",
       "      <td>-0.321424</td>\n",
       "      <td>6.026048</td>\n",
       "      <td>-0.098066</td>\n",
       "      <td>-0.342703</td>\n",
       "      <td>-0.270048</td>\n",
       "      <td>-0.414189</td>\n",
       "      <td>-0.135084</td>\n",
       "      <td>-0.073187</td>\n",
       "      <td>-0.361531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.325261</td>\n",
       "      <td>1.195089</td>\n",
       "      <td>-0.016421</td>\n",
       "      <td>-1.323505</td>\n",
       "      <td>1.537091</td>\n",
       "      <td>-0.817431</td>\n",
       "      <td>-0.658884</td>\n",
       "      <td>-0.416594</td>\n",
       "      <td>-0.326292</td>\n",
       "      <td>-0.199462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23874</td>\n",
       "      <td>-0.321424</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-0.098066</td>\n",
       "      <td>-0.342703</td>\n",
       "      <td>-0.270048</td>\n",
       "      <td>-0.414189</td>\n",
       "      <td>-0.135084</td>\n",
       "      <td>-0.073187</td>\n",
       "      <td>2.766015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.447159</td>\n",
       "      <td>0.789334</td>\n",
       "      <td>0.952244</td>\n",
       "      <td>0.755569</td>\n",
       "      <td>-0.650579</td>\n",
       "      <td>-0.817431</td>\n",
       "      <td>1.517718</td>\n",
       "      <td>2.400418</td>\n",
       "      <td>-0.326292</td>\n",
       "      <td>-0.199462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23874</td>\n",
       "      <td>-0.321424</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-0.098066</td>\n",
       "      <td>-0.342703</td>\n",
       "      <td>-0.270048</td>\n",
       "      <td>-0.414189</td>\n",
       "      <td>-0.135084</td>\n",
       "      <td>-0.073187</td>\n",
       "      <td>2.766015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.655231</td>\n",
       "      <td>-1.239437</td>\n",
       "      <td>-0.016421</td>\n",
       "      <td>0.755569</td>\n",
       "      <td>-0.650579</td>\n",
       "      <td>-0.817431</td>\n",
       "      <td>1.517718</td>\n",
       "      <td>-0.416594</td>\n",
       "      <td>3.064738</td>\n",
       "      <td>-0.199462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23874</td>\n",
       "      <td>-0.321424</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-0.098066</td>\n",
       "      <td>-0.342703</td>\n",
       "      <td>-0.270048</td>\n",
       "      <td>-0.414189</td>\n",
       "      <td>-0.135084</td>\n",
       "      <td>-0.073187</td>\n",
       "      <td>-0.361531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        gpa      gmat  work_exp   x0_Male   x1_True  x2_Humanities   x2_STEM  \\\n",
       "0  0.325261 -0.630806 -1.953750 -1.323505 -0.650579      -0.817431 -0.658884   \n",
       "1  0.193273  0.586457 -0.016421  0.755569 -0.650579       1.223345 -0.658884   \n",
       "2  0.325261  1.195089 -0.016421 -1.323505  1.537091      -0.817431 -0.658884   \n",
       "3  1.447159  0.789334  0.952244  0.755569 -0.650579      -0.817431  1.517718   \n",
       "4  0.655231 -1.239437 -0.016421  0.755569 -0.650579      -0.817431  1.517718   \n",
       "\n",
       "   x3_Black  x3_Hispanic  x3_Other  ...  x4_Health Care  \\\n",
       "0 -0.416594    -0.326292 -0.199462  ...        -0.23874   \n",
       "1  2.400418    -0.326292 -0.199462  ...        -0.23874   \n",
       "2 -0.416594    -0.326292 -0.199462  ...        -0.23874   \n",
       "3  2.400418    -0.326292 -0.199462  ...        -0.23874   \n",
       "4 -0.416594     3.064738 -0.199462  ...        -0.23874   \n",
       "\n",
       "   x4_Investment Banking  x4_Investment Management  x4_Media/Entertainment  \\\n",
       "0              -0.321424                 -0.165946               -0.098066   \n",
       "1              -0.321424                  6.026048               -0.098066   \n",
       "2              -0.321424                 -0.165946               -0.098066   \n",
       "3              -0.321424                 -0.165946               -0.098066   \n",
       "4              -0.321424                 -0.165946               -0.098066   \n",
       "\n",
       "   x4_Nonprofit/Gov  x4_Other  x4_PE/VC  x4_Real Estate  x4_Retail  \\\n",
       "0         -0.342703 -0.270048 -0.414189       -0.135084  -0.073187   \n",
       "1         -0.342703 -0.270048 -0.414189       -0.135084  -0.073187   \n",
       "2         -0.342703 -0.270048 -0.414189       -0.135084  -0.073187   \n",
       "3         -0.342703 -0.270048 -0.414189       -0.135084  -0.073187   \n",
       "4         -0.342703 -0.270048 -0.414189       -0.135084  -0.073187   \n",
       "\n",
       "   x4_Technology  \n",
       "0      -0.361531  \n",
       "1      -0.361531  \n",
       "2       2.766015  \n",
       "3       2.766015  \n",
       "4      -0.361531  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = pd.Series(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5194\n",
       "1    5194\n",
       "2    5194\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=42, stratify=y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10907, 25), (4675, 25), (10907,), (4675,))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3636\n",
       "0    3636\n",
       "2    3635\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to evaluate model\n",
    "def evaluate_model(actual, pred):\n",
    "    '''\n",
    "    Function to evaluate model performance\n",
    "\n",
    "    Args:\n",
    "    actual : Actual/True label\n",
    "    pred : Predicted label\n",
    "\n",
    "    Returns:\n",
    "    accuracy : accuracy score\n",
    "    matrix : confusion matrix\n",
    "    report : classification report\n",
    "    '''\n",
    "    accuracy = accuracy_score(actual, pred)\n",
    "    matrix = confusion_matrix(actual, pred)\n",
    "    report = classification_report(actual, pred)\n",
    "    \n",
    "    return accuracy, matrix, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Before oversampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.6192423003543199\n",
      "\n",
      "- Confusion matrix: \n",
      "[[2010  555 1104]\n",
      " [ 609 2518  542]\n",
      " [ 875  506 2288]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.55      0.56      3669\n",
      "           1       0.70      0.69      0.69      3669\n",
      "           2       0.58      0.62      0.60      3669\n",
      "\n",
      "    accuracy                           0.62     11007\n",
      "   macro avg       0.62      0.62      0.62     11007\n",
      "weighted avg       0.62      0.62      0.62     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.6503496503496503\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 158   55   86]\n",
      " [ 241 1038  246]\n",
      " [   9   13   13]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.53      0.45       299\n",
      "           1       0.94      0.68      0.79      1525\n",
      "           2       0.04      0.37      0.07        35\n",
      "\n",
      "    accuracy                           0.65      1859\n",
      "   macro avg       0.45      0.53      0.43      1859\n",
      "weighted avg       0.83      0.65      0.72      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "1.0\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3669    0    0]\n",
      " [   0 3669    0]\n",
      " [   0    0 3669]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3669\n",
      "           1       1.00      1.00      1.00      3669\n",
      "           2       1.00      1.00      1.00      3669\n",
      "\n",
      "    accuracy                           1.00     11007\n",
      "   macro avg       1.00      1.00      1.00     11007\n",
      "weighted avg       1.00      1.00      1.00     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.8192576654115116\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 152  144    3]\n",
      " [ 155 1368    2]\n",
      " [  14   18    3]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.51      0.49       299\n",
      "           1       0.89      0.90      0.90      1525\n",
      "           2       0.38      0.09      0.14        35\n",
      "\n",
      "    accuracy                           0.82      1859\n",
      "   macro avg       0.58      0.50      0.51      1859\n",
      "weighted avg       0.82      0.82      0.82      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.7904061052057781\n",
      "\n",
      "- Confusion matrix: \n",
      "[[2906  286  477]\n",
      " [ 687 2909   73]\n",
      " [ 688   96 2885]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73      3669\n",
      "           1       0.88      0.79      0.84      3669\n",
      "           2       0.84      0.79      0.81      3669\n",
      "\n",
      "    accuracy                           0.79     11007\n",
      "   macro avg       0.80      0.79      0.79     11007\n",
      "weighted avg       0.80      0.79      0.79     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.7719203873050027\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 211   77   11]\n",
      " [ 271 1218   36]\n",
      " [  12   17    6]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.71      0.53       299\n",
      "           1       0.93      0.80      0.86      1525\n",
      "           2       0.11      0.17      0.14        35\n",
      "\n",
      "    accuracy                           0.77      1859\n",
      "   macro avg       0.49      0.56      0.51      1859\n",
      "weighted avg       0.83      0.77      0.79      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.9028799854637958\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3267  209  193]\n",
      " [ 418 3247    4]\n",
      " [ 220   25 3424]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86      3669\n",
      "           1       0.93      0.88      0.91      3669\n",
      "           2       0.95      0.93      0.94      3669\n",
      "\n",
      "    accuracy                           0.90     11007\n",
      "   macro avg       0.90      0.90      0.90     11007\n",
      "weighted avg       0.90      0.90      0.90     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.8068854222700377\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 180  117    2]\n",
      " [ 203 1315    7]\n",
      " [  16   14    5]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.60      0.52       299\n",
      "           1       0.91      0.86      0.89      1525\n",
      "           2       0.36      0.14      0.20        35\n",
      "\n",
      "    accuracy                           0.81      1859\n",
      "   macro avg       0.57      0.54      0.54      1859\n",
      "weighted avg       0.83      0.81      0.81      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "SVM\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.904606159716544\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3381  109  179]\n",
      " [ 635 2911  123]\n",
      " [   4    0 3665]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88      3669\n",
      "           1       0.96      0.79      0.87      3669\n",
      "           2       0.92      1.00      0.96      3669\n",
      "\n",
      "    accuracy                           0.90     11007\n",
      "   macro avg       0.91      0.90      0.90     11007\n",
      "weighted avg       0.91      0.90      0.90     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.7143625605164067\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 176   87   36]\n",
      " [ 317 1150   58]\n",
      " [  19   14    2]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.59      0.43       299\n",
      "           1       0.92      0.75      0.83      1525\n",
      "           2       0.02      0.06      0.03        35\n",
      "\n",
      "    accuracy                           0.71      1859\n",
      "   macro avg       0.43      0.47      0.43      1859\n",
      "weighted avg       0.81      0.71      0.75      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "1.0\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3669    0    0]\n",
      " [   0 3669    0]\n",
      " [   0    0 3669]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3669\n",
      "           1       1.00      1.00      1.00      3669\n",
      "           2       1.00      1.00      1.00      3669\n",
      "\n",
      "    accuracy                           1.00     11007\n",
      "   macro avg       1.00      1.00      1.00     11007\n",
      "weighted avg       1.00      1.00      1.00     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.7977407208176439\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 147  133   19]\n",
      " [ 172 1333   20]\n",
      " [  17   15    3]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.49      0.46       299\n",
      "           1       0.90      0.87      0.89      1525\n",
      "           2       0.07      0.09      0.08        35\n",
      "\n",
      "    accuracy                           0.80      1859\n",
      "   macro avg       0.47      0.48      0.48      1859\n",
      "weighted avg       0.81      0.80      0.80      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "KNN\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.9242300354319978\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3631   17   21]\n",
      " [ 687 2873  109]\n",
      " [   0    0 3669]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91      3669\n",
      "           1       0.99      0.78      0.88      3669\n",
      "           2       0.97      1.00      0.98      3669\n",
      "\n",
      "    accuracy                           0.92     11007\n",
      "   macro avg       0.93      0.92      0.92     11007\n",
      "weighted avg       0.93      0.92      0.92     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.6691769768692846\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 170   98   31]\n",
      " [ 381 1073   71]\n",
      " [  18   16    1]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.57      0.39       299\n",
      "           1       0.90      0.70      0.79      1525\n",
      "           2       0.01      0.03      0.01        35\n",
      "\n",
      "    accuracy                           0.67      1859\n",
      "   macro avg       0.40      0.43      0.40      1859\n",
      "weighted avg       0.79      0.67      0.71      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBoost\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.9970927591532661\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3647   22    0]\n",
      " [   9 3660    0]\n",
      " [   0    1 3668]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      3669\n",
      "           1       0.99      1.00      1.00      3669\n",
      "           2       1.00      1.00      1.00      3669\n",
      "\n",
      "    accuracy                           1.00     11007\n",
      "   macro avg       1.00      1.00      1.00     11007\n",
      "weighted avg       1.00      1.00      1.00     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.8294782140935987\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 126  171    2]\n",
      " [ 110 1412    3]\n",
      " [   9   22    4]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.42      0.46       299\n",
      "           1       0.88      0.93      0.90      1525\n",
      "           2       0.44      0.11      0.18        35\n",
      "\n",
      "    accuracy                           0.83      1859\n",
      "   macro avg       0.61      0.49      0.52      1859\n",
      "weighted avg       0.81      0.83      0.82      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression' : LogisticRegression(),\n",
    "    'Random Forest' : RandomForestClassifier(),\n",
    "    'AdaBoost' : AdaBoostClassifier(),\n",
    "    'Gradient Boosting' : GradientBoostingClassifier(),\n",
    "    'SVM' : SVC(),\n",
    "    'Decision Tree' : DecisionTreeClassifier(),\n",
    "    'KNN' : KNeighborsClassifier(),\n",
    "    'XGBoost' : XGBClassifier()\n",
    "}\n",
    "\n",
    "model_list = []\n",
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values()) [i]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # evaluate train and test performance\n",
    "    train_model_accuracy, train_model_matrix, train_model_report = evaluate_model(y_train, y_train_pred)\n",
    "    test_model_accuracy, test_model_matrix, test_model_report = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(f\"- Accuracy: \\n{train_model_accuracy}\", end='\\n\\n')\n",
    "    print(f\"- Confusion matrix: \\n{train_model_matrix}\", end='\\n\\n')\n",
    "    print(f\"- Classification report: \\n{train_model_report}\", end='\\n\\n')\n",
    "    train_accuracy_list.append(train_model_accuracy)\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(f\"- Accuracy: \\n{test_model_accuracy}\", end='\\n\\n')\n",
    "    print(f\"- Confusion matrix: \\n {test_model_matrix}\", end='\\n\\n')\n",
    "    print(f\"- Classification report: \\n {test_model_report}\", end='\\n\\n')\n",
    "    test_accuracy_list.append(test_model_accuracy)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **After Oversamling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.5968643990098103\n",
      "\n",
      "- Confusion matrix: \n",
      "[[2090  542 1004]\n",
      " [ 606 2421  609]\n",
      " [ 977  659 1999]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57      3636\n",
      "           1       0.67      0.67      0.67      3636\n",
      "           2       0.55      0.55      0.55      3635\n",
      "\n",
      "    accuracy                           0.60     10907\n",
      "   macro avg       0.60      0.60      0.60     10907\n",
      "weighted avg       0.60      0.60      0.60     10907\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.6027807486631016\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 893  223  442]\n",
      " [ 279 1038  241]\n",
      " [ 407  265  887]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57      1558\n",
      "           1       0.68      0.67      0.67      1558\n",
      "           2       0.56      0.57      0.57      1559\n",
      "\n",
      "    accuracy                           0.60      4675\n",
      "   macro avg       0.60      0.60      0.60      4675\n",
      "weighted avg       0.60      0.60      0.60      4675\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.9997249472815622\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3635    1    0]\n",
      " [   2 3634    0]\n",
      " [   0    0 3635]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3636\n",
      "           1       1.00      1.00      1.00      3636\n",
      "           2       1.00      1.00      1.00      3635\n",
      "\n",
      "    accuracy                           1.00     10907\n",
      "   macro avg       1.00      1.00      1.00     10907\n",
      "weighted avg       1.00      1.00      1.00     10907\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.9189304812834225\n",
      "\n",
      "- Confusion matrix: \n",
      " [[1425  103   30]\n",
      " [ 213 1333   12]\n",
      " [   5   16 1538]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      1558\n",
      "           1       0.92      0.86      0.89      1558\n",
      "           2       0.97      0.99      0.98      1559\n",
      "\n",
      "    accuracy                           0.92      4675\n",
      "   macro avg       0.92      0.92      0.92      4675\n",
      "weighted avg       0.92      0.92      0.92      4675\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.7442926560924177\n",
      "\n",
      "- Confusion matrix: \n",
      "[[2746  287  603]\n",
      " [ 781 2799   56]\n",
      " [ 853  209 2573]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69      3636\n",
      "           1       0.85      0.77      0.81      3636\n",
      "           2       0.80      0.71      0.75      3635\n",
      "\n",
      "    accuracy                           0.74     10907\n",
      "   macro avg       0.76      0.74      0.75     10907\n",
      "weighted avg       0.76      0.74      0.75     10907\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.7411764705882353\n",
      "\n",
      "- Confusion matrix: \n",
      " [[1172  115  271]\n",
      " [ 365 1173   20]\n",
      " [ 348   91 1120]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68      1558\n",
      "           1       0.85      0.75      0.80      1558\n",
      "           2       0.79      0.72      0.75      1559\n",
      "\n",
      "    accuracy                           0.74      4675\n",
      "   macro avg       0.76      0.74      0.74      4675\n",
      "weighted avg       0.76      0.74      0.74      4675\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.8526634271568717\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3020  317  299]\n",
      " [ 563 3069    4]\n",
      " [ 321  103 3211]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      3636\n",
      "           1       0.88      0.84      0.86      3636\n",
      "           2       0.91      0.88      0.90      3635\n",
      "\n",
      "    accuracy                           0.85     10907\n",
      "   macro avg       0.86      0.85      0.85     10907\n",
      "weighted avg       0.86      0.85      0.85     10907\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.8295187165775401\n",
      "\n",
      "- Confusion matrix: \n",
      " [[1246  155  157]\n",
      " [ 284 1273    1]\n",
      " [ 151   49 1359]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      1558\n",
      "           1       0.86      0.82      0.84      1558\n",
      "           2       0.90      0.87      0.88      1559\n",
      "\n",
      "    accuracy                           0.83      4675\n",
      "   macro avg       0.83      0.83      0.83      4675\n",
      "weighted avg       0.83      0.83      0.83      4675\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "SVM\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.8398276336297791\n",
      "\n",
      "- Confusion matrix: \n",
      "[[2967  218  451]\n",
      " [ 738 2638  260]\n",
      " [  57   23 3555]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      3636\n",
      "           1       0.92      0.73      0.81      3636\n",
      "           2       0.83      0.98      0.90      3635\n",
      "\n",
      "    accuracy                           0.84     10907\n",
      "   macro avg       0.85      0.84      0.84     10907\n",
      "weighted avg       0.85      0.84      0.84     10907\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.8130481283422459\n",
      "\n",
      "- Confusion matrix: \n",
      " [[1204  127  227]\n",
      " [ 362 1081  115]\n",
      " [  22   21 1516]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1558\n",
      "           1       0.88      0.69      0.78      1558\n",
      "           2       0.82      0.97      0.89      1559\n",
      "\n",
      "    accuracy                           0.81      4675\n",
      "   macro avg       0.82      0.81      0.81      4675\n",
      "weighted avg       0.82      0.81      0.81      4675\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.9997249472815622\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3636    0    0]\n",
      " [   3 3633    0]\n",
      " [   0    0 3635]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3636\n",
      "           1       1.00      1.00      1.00      3636\n",
      "           2       1.00      1.00      1.00      3635\n",
      "\n",
      "    accuracy                           1.00     10907\n",
      "   macro avg       1.00      1.00      1.00     10907\n",
      "weighted avg       1.00      1.00      1.00     10907\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.8626737967914438\n",
      "\n",
      "- Confusion matrix: \n",
      " [[1270  186  102]\n",
      " [ 237 1298   23]\n",
      " [  65   29 1465]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      1558\n",
      "           1       0.86      0.83      0.85      1558\n",
      "           2       0.92      0.94      0.93      1559\n",
      "\n",
      "    accuracy                           0.86      4675\n",
      "   macro avg       0.86      0.86      0.86      4675\n",
      "weighted avg       0.86      0.86      0.86      4675\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "KNN\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.9049234436600349\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3499   70   67]\n",
      " [ 742 2740  154]\n",
      " [   3    1 3631]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89      3636\n",
      "           1       0.97      0.75      0.85      3636\n",
      "           2       0.94      1.00      0.97      3635\n",
      "\n",
      "    accuracy                           0.90     10907\n",
      "   macro avg       0.91      0.90      0.90     10907\n",
      "weighted avg       0.91      0.90      0.90     10907\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.8575401069518717\n",
      "\n",
      "- Confusion matrix: \n",
      " [[1436   65   57]\n",
      " [ 443 1022   93]\n",
      " [   3    5 1551]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83      1558\n",
      "           1       0.94      0.66      0.77      1558\n",
      "           2       0.91      0.99      0.95      1559\n",
      "\n",
      "    accuracy                           0.86      4675\n",
      "   macro avg       0.87      0.86      0.85      4675\n",
      "weighted avg       0.87      0.86      0.85      4675\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBoost\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.9812964151462363\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3510  121    5]\n",
      " [  46 3589    1]\n",
      " [   9   22 3604]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      3636\n",
      "           1       0.96      0.99      0.97      3636\n",
      "           2       1.00      0.99      0.99      3635\n",
      "\n",
      "    accuracy                           0.98     10907\n",
      "   macro avg       0.98      0.98      0.98     10907\n",
      "weighted avg       0.98      0.98      0.98     10907\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.9135828877005348\n",
      "\n",
      "- Confusion matrix: \n",
      " [[1358  160   40]\n",
      " [ 168 1385    5]\n",
      " [  10   21 1528]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      1558\n",
      "           1       0.88      0.89      0.89      1558\n",
      "           2       0.97      0.98      0.98      1559\n",
      "\n",
      "    accuracy                           0.91      4675\n",
      "   macro avg       0.91      0.91      0.91      4675\n",
      "weighted avg       0.91      0.91      0.91      4675\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression' : LogisticRegression(),\n",
    "    'Random Forest' : RandomForestClassifier(),\n",
    "    'AdaBoost' : AdaBoostClassifier(),\n",
    "    'Gradient Boosting' : GradientBoostingClassifier(),\n",
    "    'SVM' : SVC(),\n",
    "    'Decision Tree' : DecisionTreeClassifier(),\n",
    "    'KNN' : KNeighborsClassifier(),\n",
    "    'XGBoost' : XGBClassifier()\n",
    "}\n",
    "\n",
    "model_list = []\n",
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values()) [i]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # evaluate train and test performance\n",
    "    train_model_accuracy, train_model_matrix, train_model_report = evaluate_model(y_train, y_train_pred)\n",
    "    test_model_accuracy, test_model_matrix, test_model_report = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(f\"- Accuracy: \\n{train_model_accuracy}\", end='\\n\\n')\n",
    "    print(f\"- Confusion matrix: \\n{train_model_matrix}\", end='\\n\\n')\n",
    "    print(f\"- Classification report: \\n{train_model_report}\", end='\\n\\n')\n",
    "    train_accuracy_list.append(train_model_accuracy)\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(f\"- Accuracy: \\n{test_model_accuracy}\", end='\\n\\n')\n",
    "    print(f\"- Confusion matrix: \\n {test_model_matrix}\", end='\\n\\n')\n",
    "    print(f\"- Classification report: \\n {test_model_report}\", end='\\n\\n')\n",
    "    test_accuracy_list.append(test_model_accuracy)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Models Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.829478</td>\n",
       "      <td>0.997093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.819258</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.806885</td>\n",
       "      <td>0.902880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.797741</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.771920</td>\n",
       "      <td>0.790406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.714363</td>\n",
       "      <td>0.904606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.669177</td>\n",
       "      <td>0.924230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.650350</td>\n",
       "      <td>0.619242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Test Accuracy  Train Accuracy\n",
       "7              XGBoost       0.829478        0.997093\n",
       "1        Random Forest       0.819258        1.000000\n",
       "3    Gradient Boosting       0.806885        0.902880\n",
       "5        Decision Tree       0.797741        1.000000\n",
       "2             AdaBoost       0.771920        0.790406\n",
       "4                  SVM       0.714363        0.904606\n",
       "6                  KNN       0.669177        0.924230\n",
       "0  Logistic Regression       0.650350        0.619242"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(list(zip(model_list, test_accuracy_list, train_accuracy_list)), columns=['Model', 'Test Accuracy', 'Train Accuracy']).sort_values(by=['Test Accuracy', 'Train Accuracy'], ascending=False)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Most of the models are overfitting and LR is underfitting, so we'll choose AdaBoost for this problem statement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoost is 0.8187197417966648\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  66  232    1]\n",
      " [  65 1456    4]\n",
      " [   6   29    0]]\n"
     ]
    }
   ],
   "source": [
    "# prediction for actual data\n",
    "ada_boost = AdaBoostClassifier()\n",
    "ada_boost.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ada_boost.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy of AdaBoost is {score}', end='\\n\\n')\n",
    "print(f'Confusion Matrix: \\n {matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoost is 0.7719203873050027\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 211   77   11]\n",
      " [ 271 1218   36]\n",
      " [  12   17    6]]\n"
     ]
    }
   ],
   "source": [
    "# prediction for oversampled data\n",
    "ada_boost = AdaBoostClassifier()\n",
    "ada_boost.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "y_pred = ada_boost.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy of AdaBoost is {score}', end='\\n\\n')\n",
    "print(f'Confusion Matrix: \\n {matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns = numeric_features.tolist() + list(preprocessor.named_transformers_['cat'].named_steps['encoder'].get_feature_names_out()))\n",
    "\n",
    "y_train = pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3669\n",
       "1    3669\n",
       "2    3669\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.Series(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1525\n",
       "0     299\n",
       "2      35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.6133369673843917\n",
      "\n",
      "- Confusion matrix: \n",
      "[[1997  588 1084]\n",
      " [ 611 2427  631]\n",
      " [ 902  440 2327]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.54      0.56      3669\n",
      "           1       0.70      0.66      0.68      3669\n",
      "           2       0.58      0.63      0.60      3669\n",
      "\n",
      "    accuracy                           0.61     11007\n",
      "   macro avg       0.62      0.61      0.61     11007\n",
      "weighted avg       0.62      0.61      0.61     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.64228079612695\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 155   56   88]\n",
      " [ 236 1029  260]\n",
      " [  10   15   10]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.52      0.44       299\n",
      "           1       0.94      0.67      0.78      1525\n",
      "           2       0.03      0.29      0.05        35\n",
      "\n",
      "    accuracy                           0.64      1859\n",
      "   macro avg       0.45      0.49      0.43      1859\n",
      "weighted avg       0.83      0.64      0.72      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.9997274461706187\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3669    0    0]\n",
      " [   3 3666    0]\n",
      " [   0    0 3669]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3669\n",
      "           1       1.00      1.00      1.00      3669\n",
      "           2       1.00      1.00      1.00      3669\n",
      "\n",
      "    accuracy                           1.00     11007\n",
      "   macro avg       1.00      1.00      1.00     11007\n",
      "weighted avg       1.00      1.00      1.00     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.7939752555137171\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 116  181    2]\n",
      " [ 157 1360    8]\n",
      " [  10   25    0]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.39      0.40       299\n",
      "           1       0.87      0.89      0.88      1525\n",
      "           2       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.79      1859\n",
      "   macro avg       0.43      0.43      0.43      1859\n",
      "weighted avg       0.78      0.79      0.79      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.7712364858726265\n",
      "\n",
      "- Confusion matrix: \n",
      "[[2819  311  539]\n",
      " [ 748 2873   48]\n",
      " [ 723  149 2797]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71      3669\n",
      "           1       0.86      0.78      0.82      3669\n",
      "           2       0.83      0.76      0.79      3669\n",
      "\n",
      "    accuracy                           0.77     11007\n",
      "   macro avg       0.78      0.77      0.77     11007\n",
      "weighted avg       0.78      0.77      0.77     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.7552447552447552\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 196   94    9]\n",
      " [ 294 1206   25]\n",
      " [  18   15    2]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.66      0.49       299\n",
      "           1       0.92      0.79      0.85      1525\n",
      "           2       0.06      0.06      0.06        35\n",
      "\n",
      "    accuracy                           0.76      1859\n",
      "   macro avg       0.45      0.50      0.46      1859\n",
      "weighted avg       0.82      0.76      0.78      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.8762605614608885\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3099  312  258]\n",
      " [ 479 3175   15]\n",
      " [ 242   56 3371]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      3669\n",
      "           1       0.90      0.87      0.88      3669\n",
      "           2       0.93      0.92      0.92      3669\n",
      "\n",
      "    accuracy                           0.88     11007\n",
      "   macro avg       0.88      0.88      0.88     11007\n",
      "weighted avg       0.88      0.88      0.88     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.78375470683163\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 159  139    1]\n",
      " [ 222 1298    5]\n",
      " [  12   23    0]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.53      0.46       299\n",
      "           1       0.89      0.85      0.87      1525\n",
      "           2       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.78      1859\n",
      "   macro avg       0.43      0.46      0.44      1859\n",
      "weighted avg       0.79      0.78      0.79      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "SVM\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.8749886435904425\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3242  160  267]\n",
      " [ 726 2742  201]\n",
      " [  14    8 3647]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85      3669\n",
      "           1       0.94      0.75      0.83      3669\n",
      "           2       0.89      0.99      0.94      3669\n",
      "\n",
      "    accuracy                           0.87     11007\n",
      "   macro avg       0.88      0.87      0.87     11007\n",
      "weighted avg       0.88      0.87      0.87     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.6826250672404519\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 175   88   36]\n",
      " [ 348 1093   84]\n",
      " [  17   17    1]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.59      0.42       299\n",
      "           1       0.91      0.72      0.80      1525\n",
      "           2       0.01      0.03      0.01        35\n",
      "\n",
      "    accuracy                           0.68      1859\n",
      "   macro avg       0.41      0.44      0.41      1859\n",
      "weighted avg       0.80      0.68      0.73      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.9997274461706187\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3669    0    0]\n",
      " [   3 3666    0]\n",
      " [   0    0 3669]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3669\n",
      "           1       1.00      1.00      1.00      3669\n",
      "           2       1.00      1.00      1.00      3669\n",
      "\n",
      "    accuracy                           1.00     11007\n",
      "   macro avg       1.00      1.00      1.00     11007\n",
      "weighted avg       1.00      1.00      1.00     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.7579343733189887\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 119  165   15]\n",
      " [ 202 1288   35]\n",
      " [  13   20    2]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.40      0.38       299\n",
      "           1       0.87      0.84      0.86      1525\n",
      "           2       0.04      0.06      0.05        35\n",
      "\n",
      "    accuracy                           0.76      1859\n",
      "   macro avg       0.42      0.43      0.43      1859\n",
      "weighted avg       0.78      0.76      0.77      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "KNN\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.91841555373853\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3590   43   36]\n",
      " [ 695 2851  123]\n",
      " [   0    1 3668]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90      3669\n",
      "           1       0.98      0.78      0.87      3669\n",
      "           2       0.96      1.00      0.98      3669\n",
      "\n",
      "    accuracy                           0.92     11007\n",
      "   macro avg       0.93      0.92      0.92     11007\n",
      "weighted avg       0.93      0.92      0.92     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.6643356643356644\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 165  104   30]\n",
      " [ 388 1069   68]\n",
      " [  15   19    1]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.55      0.38       299\n",
      "           1       0.90      0.70      0.79      1525\n",
      "           2       0.01      0.03      0.01        35\n",
      "\n",
      "    accuracy                           0.66      1859\n",
      "   macro avg       0.40      0.43      0.39      1859\n",
      "weighted avg       0.78      0.66      0.71      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBoost\n",
      "Model performance for Training set\n",
      "- Accuracy: \n",
      "0.9850095393840284\n",
      "\n",
      "- Confusion matrix: \n",
      "[[3573   88    8]\n",
      " [  50 3617    2]\n",
      " [   4   13 3652]]\n",
      "\n",
      "- Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3669\n",
      "           1       0.97      0.99      0.98      3669\n",
      "           2       1.00      1.00      1.00      3669\n",
      "\n",
      "    accuracy                           0.99     11007\n",
      "   macro avg       0.99      0.99      0.99     11007\n",
      "weighted avg       0.99      0.99      0.99     11007\n",
      "\n",
      "\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: \n",
      "0.7902097902097902\n",
      "\n",
      "- Confusion matrix: \n",
      " [[ 100  198    1]\n",
      " [ 152 1369    4]\n",
      " [   3   32    0]]\n",
      "\n",
      "- Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.33      0.36       299\n",
      "           1       0.86      0.90      0.88      1525\n",
      "           2       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.79      1859\n",
      "   macro avg       0.42      0.41      0.41      1859\n",
      "weighted avg       0.77      0.79      0.78      1859\n",
      "\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression' : LogisticRegression(),\n",
    "    'Random Forest' : RandomForestClassifier(),\n",
    "    'AdaBoost' : AdaBoostClassifier(),\n",
    "    'Gradient Boosting' : GradientBoostingClassifier(),\n",
    "    'SVM' : SVC(),\n",
    "    'Decision Tree' : DecisionTreeClassifier(),\n",
    "    'KNN' : KNeighborsClassifier(),\n",
    "    'XGBoost' : XGBClassifier()\n",
    "}\n",
    "\n",
    "model_list = []\n",
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values()) [i]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # evaluate train and test performance\n",
    "    train_model_accuracy, train_model_matrix, train_model_report = evaluate_model(y_train, y_train_pred)\n",
    "    test_model_accuracy, test_model_matrix, test_model_report = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(f\"- Accuracy: \\n{train_model_accuracy}\", end='\\n\\n')\n",
    "    print(f\"- Confusion matrix: \\n{train_model_matrix}\", end='\\n\\n')\n",
    "    print(f\"- Classification report: \\n{train_model_report}\", end='\\n\\n')\n",
    "    train_accuracy_list.append(train_model_accuracy)\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(f\"- Accuracy: \\n{test_model_accuracy}\", end='\\n\\n')\n",
    "    print(f\"- Confusion matrix: \\n {test_model_matrix}\", end='\\n\\n')\n",
    "    print(f\"- Classification report: \\n {test_model_report}\", end='\\n\\n')\n",
    "    test_accuracy_list.append(test_model_accuracy)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "admission",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
