{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ayush\\\\OneDrive - Sujal Dhungana\\\\MBA Admission Classification Project\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ayush\\\\OneDrive - Sujal Dhungana\\\\MBA Admission Classification Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from src import *\n",
    "from src.logger import logging\n",
    "from src.exception import CustomException\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from src.utils.common import read_yaml_file, create_directory, save_object, load_object, save_transformed_data\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    preprocessor_obj_path: Path\n",
    "    train_arr: Path\n",
    "    test_arr: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                  config_file_path = CONFIG_FILE_PATH,\n",
    "                  params_file_path = PARAMS_FILE_PATH):\n",
    "        try:\n",
    "            self.config = read_yaml_file(config_file_path)\n",
    "\n",
    "            logging.info(\"Configuration and Parameters files have been read successfully\")\n",
    "\n",
    "            logging.info(\"Creating directories to store artifacts\")\n",
    "            create_directory([self.config.artifacts_directory])\n",
    "            logging.info(\"Directories have been created successfully\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        try:\n",
    "            logging.info(\"Getting data transformation config\")\n",
    "            config = self.config.data_transformation\n",
    "\n",
    "            logging.info(\"Creating directories to store transformed data\")\n",
    "            create_directory([config.root_dir])\n",
    "\n",
    "            logging.info(\"Directories have been created successfully to store transformed data\")\n",
    "\n",
    "            logging.info(\"Returning data transformation config\")\n",
    "            data_transformation_config = DataTransformationConfig(\n",
    "                preprocessor_obj_path = config.preprocessor_obj_path,\n",
    "                train_arr = config.train_arr_path,\n",
    "                test_arr = config.test_arr_path\n",
    "            )\n",
    "\n",
    "            return data_transformation_config\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, \n",
    "                 config: DataTransformationConfig):\n",
    "        \n",
    "        self.config = config\n",
    "    \n",
    "    def create_preprocessor(self):\n",
    "        '''\n",
    "        This function creates a preprocessor object and saves it to the path specified in the configuration file\n",
    "\n",
    "        Returns:\n",
    "        preprocessor: ColumnTransformer object\n",
    "        '''\n",
    "        try:\n",
    "            logging.info(\"Specifying the numerical and categorical features\")\n",
    "            numerical_features = ['gpa', 'gmat', 'work_exp']\n",
    "            categorical_features = [\n",
    "                    'gender',\n",
    "                    'international',\n",
    "                    'major',\n",
    "                    'race',\n",
    "                    'work_industry'\n",
    "            ]\n",
    "\n",
    "            logging.info(\"Creating a numerical pipeline\")\n",
    "            num_pipeline = Pipeline(\n",
    "                steps=[\n",
    "                    ('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler())\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            logging.info(\"Successfully created numerical pipeline\")\n",
    "\n",
    "            logging.info(\"Creating a categorical pipeline\")\n",
    "            cat_pipeline = Pipeline(\n",
    "                steps=[\n",
    "                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                    ('encoder', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False))\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            logging.info(\"Successfully created categorical pipeline\")\n",
    "\n",
    "            logging.info(\"Creating a column transformer\")\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num', num_pipeline, numerical_features),\n",
    "                    ('cat', cat_pipeline, categorical_features)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            logging.info(\"Successfully created column transformer\")\n",
    "\n",
    "            logging.info(\"Saving the preprocessor object to the specified path\")\n",
    "            save_object(\n",
    "                object= preprocessor, \n",
    "                object_path = self.config.preprocessor_obj_path\n",
    "                )\n",
    "            logging.info(\"Preprocessor object has been saved successfully\")\n",
    "\n",
    "            logging.info(\"Returning the preprocessor object\")\n",
    "            return preprocessor\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "\n",
    "    def initiate_data_transformation(self, training_data_path, testing_data_path):\n",
    "        '''\n",
    "        This function transforms the data using the preprocessor object\n",
    "\n",
    "        Returns:\n",
    "        transformed_data: DataFrame\n",
    "        '''\n",
    "        try:\n",
    "            logging.info(\"Reading the training and testing data\")\n",
    "            train_data = pd.read_csv(training_data_path)\n",
    "            test_data = pd.read_csv(testing_data_path)\n",
    "\n",
    "            logging.info(\"Data has been read successfully\")\n",
    "\n",
    "            logging.info(\"Replacing empty strings with 'Rejected' in the admission column\")\n",
    "            train_data['admission'] = train_data['admission'].replace('', 'Rejected')\n",
    "            test_data['admission'] = test_data['admission'].replace('', 'Rejected')\n",
    "\n",
    "            logging.info(\"Splitting the data into input features and target feature\")\n",
    "            target = ['admission']\n",
    "\n",
    "            train_input_features = train_data.drop(columns=['admission', 'application_id'], axis=1)\n",
    "            train_target_feature = train_data[target]\n",
    "\n",
    "            test_input_features = test_data.drop(columns=['admission', 'application_id'], axis=1)\n",
    "            test_target_feature = test_data[target]\n",
    "\n",
    "            logging.info(\"Initializing the preprocessor object\")\n",
    "            preprocessor = self.create_preprocessor()\n",
    "            \n",
    "            logging.info(\"Preprocessor object has been initialized successfully\")\n",
    "\n",
    "            logging.info(\"Transforming the training data\")\n",
    "            transformed_train_data = preprocessor.fit_transform(train_input_features)\n",
    "            logging.info(\"Training data has been transformed successfully\")\n",
    "\n",
    "            logging.info(\"Transforming the testing data\")\n",
    "            transformed_test_data = preprocessor.transform(test_input_features)\n",
    "            logging.info(\"Testing data has been transformed successfully\")\n",
    "\n",
    "            logging.info(\"Initializing the target encoder\")\n",
    "            target_encoder = LabelEncoder()\n",
    "\n",
    "            logging.info(\"Fitting the target encoder on the training target feature\")\n",
    "            target_encoder.fit(train_target_feature)\n",
    "\n",
    "            logging.info(\"Transforming the training target feature\")\n",
    "            transformed_train_target = target_encoder.transform(train_target_feature)\n",
    "\n",
    "\n",
    "            logging.info(\"Combining the transformed training data and target feature\")\n",
    "            train_arr = np.c_[\n",
    "                transformed_train_data,\n",
    "                transformed_train_target\n",
    "            ]\n",
    "\n",
    "            logging.info(\"Combining the transformed testing data and target feature\")\n",
    "            test_arr = np.c_[\n",
    "                transformed_test_data,\n",
    "                test_target_feature\n",
    "            ]\n",
    "\n",
    "            logging.info(\"Saving the transformed trained data\")\n",
    "            save_transformed_data(\n",
    "                data = train_arr, \n",
    "                path = self.config.train_arr\n",
    "            )\n",
    "\n",
    "            logging.info(\"Succesfully saved transformed train data\")\n",
    "            \n",
    "            logging.info(\"Saving the transformed test data\")\n",
    "            save_transformed_data(\n",
    "                data = test_arr,\n",
    "                path = self.config.test_arr\n",
    "            )\n",
    "\n",
    "            logging.info(\"Succesfully saved transformed train data\")\n",
    "\n",
    "\n",
    "            logging.info(\"Returning the transformed data\")\n",
    "\n",
    "            return train_arr, test_arr\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        config_manager = ConfigurationManager()\n",
    "        data_transformation_config = config_manager.get_data_transformation_config()\n",
    "        data_transformation = DataTransformation(data_transformation_config)\n",
    "        data_transformation.initiate_data_transformation(\n",
    "            training_data_path='artifacts/data_ingestion/train_data.csv', \n",
    "            testing_data_path='artifacts/data_ingestion/test_data.csv')\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        raise CustomException(e, sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "admission",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
